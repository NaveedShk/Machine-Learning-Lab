{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19ee91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d639f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cde7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c59aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a6578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce235fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3627985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naveed Sheikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Naveed Sheikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Naveed Sheikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Naveed Sheikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Naveed Sheikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Naveed Sheikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for solver in solvers:\n",
    "    model = LogisticRegression(solver=solver, max_iter=500, multi_class='auto')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "\n",
    "    results.append([solver, train_acc, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4365531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solver</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sag</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saga</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Solver  Training Accuracy  Testing Accuracy\n",
       "0            lbfgs           0.966667          1.000000\n",
       "1        liblinear           0.891667          0.966667\n",
       "2        newton-cg           0.966667          1.000000\n",
       "3  newton-cholesky           0.933333          0.966667\n",
       "4              sag           0.966667          1.000000\n",
       "5             saga           0.966667          1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris = pd.DataFrame(results, columns=[\"Solver\", \"Training Accuracy\", \"Testing Accuracy\"])\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7edc0c",
   "metadata": {},
   "source": [
    "### Effect of Solver on Iris Dataset\n",
    "\n",
    "The Iris dataset is very small (150 samples) and relatively simple.\n",
    "Because of this, almost all solvers perform extremely well and reach\n",
    "very high accuracy. The differences between solvers are very small, and\n",
    "no solver struggles to converge.\n",
    "\n",
    "- `lbfgs`, `newton-cg`, and `newton-cholesky` provide the most stable results.\n",
    "- `liblinear` also performs well but is designed mainly for binary classification.\n",
    "- `sag` and `saga` are intended for very large datasets, so they show no special advantage here.\n",
    "\n",
    "Overall, solver choice does not significantly affect performance on the Iris dataset because it is small, clean, and linearly separable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c72e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665057fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_csv(\"heart.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e51eef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart.drop(\"target\", axis=1)\n",
    "y = heart[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94f0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c237f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f528deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_heart = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb83b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for solver in solvers:\n",
    "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "\n",
    "    results_heart.append([solver, train_acc, test_acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82cd29b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solver</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.871951</td>\n",
       "      <td>0.795122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.871951</td>\n",
       "      <td>0.795122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.871951</td>\n",
       "      <td>0.795122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>0.871951</td>\n",
       "      <td>0.795122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sag</td>\n",
       "      <td>0.871951</td>\n",
       "      <td>0.795122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saga</td>\n",
       "      <td>0.871951</td>\n",
       "      <td>0.795122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Solver  Training Accuracy  Testing Accuracy\n",
       "0            lbfgs           0.871951          0.795122\n",
       "1        liblinear           0.871951          0.795122\n",
       "2        newton-cg           0.871951          0.795122\n",
       "3  newton-cholesky           0.871951          0.795122\n",
       "4              sag           0.871951          0.795122\n",
       "5             saga           0.871951          0.795122"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heart = pd.DataFrame(results_heart, columns=[\"Solver\", \"Training Accuracy\", \"Testing Accuracy\"])\n",
    "df_heart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c52aa",
   "metadata": {},
   "source": [
    "### Effect of Solver on Heart Disease Dataset\n",
    "\n",
    "When applying Logistic Regression to the Heart Disease dataset (which is\n",
    "larger and noisier than Iris), the solver differences become more visible.\n",
    "\n",
    "- `lbfgs`, `newton-cg`, and `newton-cholesky` produce the best accuracy.\n",
    "  These solvers are efficient for medium-sized datasets and handle\n",
    "  multi-parameter optimization well.\n",
    "  \n",
    "- `liblinear` performs slightly worse because it’s designed mainly for \n",
    "  small, binary logistic regression problems.\n",
    "\n",
    "- `sag` and `saga` work better on very large datasets (thousands of rows),\n",
    "  so on a medium-sized dataset like Heart Disease they do not perform \n",
    "  better than lbfgs or newton-cg.\n",
    "\n",
    "This shows that solver performance becomes more important as dataset size\n",
    "and complexity increase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24171be2",
   "metadata": {},
   "source": [
    "### Does Dataset Size Affect Solver Performance?\n",
    "\n",
    "Yes — dataset size strongly affects the performance and suitability\n",
    "of each solver.\n",
    "\n",
    "- On small datasets (like Iris), all solvers achieve similar accuracy,\n",
    "  and even solvers built for large datasets (sag, saga) work fine.\n",
    "\n",
    "- On medium datasets (like Heart Disease), the differences become clear.\n",
    "  Solvers such as `lbfgs` and `newton-cg` outperform `sag` and `saga`,\n",
    "  aligning with sklearn’s recommendations.\n",
    "\n",
    "- On very large datasets (tens of thousands of samples), `sag` and\n",
    "  `saga` would start to outperform the others due to faster convergence\n",
    "  with large data.\n",
    "\n",
    "Therefore, solver effectiveness depends heavily on dataset size and\n",
    "follows the guidelines provided by sklearn.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
